{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Project inspired by the following article: \n",
    "https://learnopencv.com/driver-drowsiness-detection-using-mediapipe-in-python/\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10384496/#:~:text=The%20overall%20performance%20of%20the,%25%20for%20left%2Dsided%20falling.\n",
    "\n",
    "database: \n",
    "https://www.kaggle.com/code/scratchpad/notebook18b582f770/edit\n",
    "\n",
    "Notice that I can choose the coordinates that you wish to analyze with opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intial imports: \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "# from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "# import streamlit as st\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "import requests\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first extract the necessary landmarks for the face and yawning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_file(csv_file, num_dimension = 3, num_coords = 33 + 21 + 21):\n",
    "    rows = []\n",
    "    #creating empty file in folder, i added the start_time in the name of the csv file, so that if a symbol appears many times in a video, it will still be created in two different csv files, just that they will have different starting times\n",
    "    # csv_file = f\"/users/aly/documents/programming/apps/machine learning/asl converter/training_models/mediapipe/demo_test/demo.csv\"\n",
    "    # csv_file=\"d:/personnel/other learning/programming/personal_projects/asl_language_translation/training_models/mediapipe/demo_test/demo.csv\"\n",
    "    # if os.path.exists(csv_file):\n",
    "    #     return \n",
    "\n",
    "\n",
    "\n",
    "# Setup CSV File for the videos\n",
    "# 21 right hand landmarks, 21 left hand landmarks, 33 pose landmarks\n",
    "    # num_coords = 33 + 21 + 21\n",
    "    landmarks = []\n",
    "\n",
    "    # we are only working with x, y\n",
    "    if num_dimension == 2:\n",
    "        for val in range(1, num_coords+1):\n",
    "            landmarks += ['x{}'.format(val), 'y{}'.format(val)]#.format(val), 'z{}'.format(val)]#, 'v{}'.format(val)]\n",
    "    \n",
    "    elif num_dimension == 3:\n",
    "        for val in range(1, num_coords+1):\n",
    "            landmarks += ['x{}'.format(val), 'y{}'.format(val).format(val), 'z{}'.format(val)]#, 'v{}'.format(val)]\n",
    "    \n",
    "    # I will assume they just want all the coordinates:\n",
    "    else:\n",
    "        landmarks += ['x{}'.format(val), 'y{}'.format(val).format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "\n",
    "    print(\"Initialized an empty landmarks of size:\", len(landmarks))\n",
    "\n",
    "    with open(csv_file, mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the landmarks chosen and writing only those out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    *,\n",
    "    img_dt,\n",
    "    img_eye_lmks=None,\n",
    "    img_eye_lmks_chosen=None,\n",
    "    face_landmarks=None,\n",
    "    ts_thickness=1,\n",
    "    ts_circle_radius=2,\n",
    "    lmk_circle_radius=3,\n",
    "    name=\"1\",\n",
    "):\n",
    "    # For plotting Face Tessellation\n",
    "    image_drawing_tool = img_dt \n",
    "     \n",
    "     # For plotting all eye landmarks\n",
    "    image_eye_lmks = img_dt.copy() if img_eye_lmks is None else img_eye_lmks\n",
    "     \n",
    "    # For plotting chosen eye landmarks\n",
    "    img_eye_lmks_chosen = img_dt.copy() if img_eye_lmks_chosen is None else img_eye_lmks_chosen\n",
    " \n",
    "    # Initializing drawing utilities for plotting face mesh tessellation\n",
    "    connections_drawing_spec = mp_drawing.DrawingSpec(\n",
    "        thickness=ts_thickness, \n",
    "        circle_radius=ts_circle_radius, \n",
    "        color=(255, 255, 255)\n",
    "    )\n",
    " \n",
    "    # Initialize a matplotlib figure.\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    fig.set_facecolor(\"white\")\n",
    " \n",
    "    # Draw landmarks on face using the drawing utilities.\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image=image_drawing_tool,\n",
    "        landmark_list=face_landmarks,\n",
    "        connections=mp_facemesh.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=connections_drawing_spec,\n",
    "    )\n",
    " \n",
    "    # Get the object which holds the x, y, and z coordinates for each landmark\n",
    "    landmarks = face_landmarks.landmark\n",
    " \n",
    "    # Iterate over all landmarks.\n",
    "    # If the landmark_idx is present in either all_idxs or all_chosen_idxs,\n",
    "    # get the denormalized coordinates and plot circles at those coordinates.\n",
    " \n",
    "    for landmark_idx, landmark in enumerate(landmarks):\n",
    "        if landmark_idx in all_idxs:\n",
    "            pred_cord = denormalize_coordinates(landmark.x, \n",
    "                                                landmark.y, \n",
    "                                                imgW, imgH)\n",
    "            cv2.circle(image_eye_lmks, \n",
    "                       pred_cord, \n",
    "                       lmk_circle_radius, \n",
    "                       (255, 255, 255), \n",
    "                       -1\n",
    "                       )\n",
    " \n",
    "        if landmark_idx in all_chosen_idxs:\n",
    "            pred_cord = denormalize_coordinates(landmark.x, \n",
    "                                                landmark.y, \n",
    "                                                imgW, imgH)\n",
    "            cv2.circle(img_eye_lmks_chosen, \n",
    "                       pred_cord, \n",
    "                       lmk_circle_radius, \n",
    "                       (255, 255, 255), \n",
    "                       -1\n",
    "                       )\n",
    " \n",
    "    # Plot post-processed images\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Face Mesh Tessellation\", fontsize=18)\n",
    "    plt.imshow(image_drawing_tool)\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"All eye landmarks\", fontsize=18)\n",
    "    plt.imshow(image_eye_lmks)\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(img_eye_lmks_chosen)\n",
    "    plt.title(\"Chosen landmarks\", fontsize=18)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture function for each part of the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_nose(image, face_landmarks, csv_file):\n",
    "    # Get nose tip coordinates.\n",
    "    nose_tip = face_landmarks.landmark[1]\n",
    "    x, y = int(nose_tip.x * image.shape[1]), int(nose_tip.y * image.shape[0])\n",
    "    \n",
    "    # Print nose tip coordinates.\n",
    "    # print(f\"Nose Tip Coordinates: (X: {x}, Y: {y})\")\n",
    "\n",
    "\n",
    "    # writing into the correct csv file\n",
    "    row = [x, y]\n",
    "    index = 0\n",
    "\n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        # basically, Krish wants the last value only, so i'll delete everything in the file\n",
    "        f.truncate(0)\n",
    "        json.dump(row, f)\n",
    "    #     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    #                     #   for row in rows:\n",
    "    #     # writerow expects a list\n",
    "    #     csv_writer.writerow(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_facemesh = mp.solutions.face_mesh\n",
    "mp_drawing  = mp.solutions.drawing_utils\n",
    "denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landmark points corresponding to left eye\n",
    "all_left_eye_idxs = list(mp_facemesh.FACEMESH_LEFT_EYE)\n",
    "# flatten and remove duplicates\n",
    "all_left_eye_idxs = set(np.ravel(all_left_eye_idxs)) \n",
    " \n",
    "# Landmark points corresponding to right eye\n",
    "all_right_eye_idxs = list(mp_facemesh.FACEMESH_RIGHT_EYE)\n",
    "all_right_eye_idxs = set(np.ravel(all_right_eye_idxs))\n",
    " \n",
    "# Combined for plotting - Landmark points for both eye\n",
    "all_idxs = all_left_eye_idxs.union(all_right_eye_idxs)\n",
    " \n",
    "# The chosen 12 points:   P1,  P2,  P3,  P4,  P5,  P6\n",
    "chosen_left_eye_idxs  = [362, 385, 387, 263, 373, 380]\n",
    "chosen_right_eye_idxs = [33,  160, 158, 133, 153, 144]\n",
    "all_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs\n",
    "\n",
    "def capture_eye(image, face_landmarks, file_name):\n",
    "    imgH, imgW, _ = image.shape\n",
    "\n",
    "    # this is an example code where the person gets the nose\n",
    "    # landmark_0 = results.multi_face_landmarks[0].landmark[0]\n",
    "\n",
    "    # note: face_landmarks = results.multi_face_landmarks[i], just at different indexes\n",
    "    rows = []\n",
    "    index = 0\n",
    "    for index in range(len(face_landmarks.landmark)):\n",
    "        if index in chosen_left_eye_idxs or index in chosen_right_eye_idxs:\n",
    "            # if index == 263:\n",
    "            #     print(\"YO\")\n",
    "            #     print(\"Total Length of '.landmark':\", len(face_landmarks.landmark))\n",
    "            \n",
    "            current_point = face_landmarks.landmark[index]\n",
    "            # print(current_point)\n",
    "            landmark_x = current_point.x * imgW \n",
    "            landmark_y = current_point.y * imgH\n",
    "            landmark_z = current_point.z * imgW #\n",
    "                \n",
    "            # print()\n",
    "            # print(\"X:\", landmark_x)\n",
    "            # print(\"Y:\", landmark_y)\n",
    "            # print(\"Z:\", landmark_z)\n",
    "            \n",
    "\n",
    "            row = [landmark_x, landmark_y, landmark_z]\n",
    "            # so yea, I am adding elements to the list called rows\n",
    "            rows += row  \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    # writing into the correct csv file\n",
    "    with open(file_name, mode='a', newline='') as f:\n",
    "        # I want to erase everything before inferring -- if we are in prediction mode\n",
    "        f.truncate(0)\n",
    "\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        #   for row in rows:\n",
    "        # writerow expects a list\n",
    "        csv_writer.writerow(rows) \n",
    "        print(\"The length of the row is \", len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of mediapipe points that represent the facial features for a yawn\n",
    "faceConnect = [234, 93, 132, 58, 172, 136, 150, 149, 176, 148, 152, 377, \n",
    "400, 378, 379, 365, 397, 367, \n",
    "288, 435, 361, 401, 323, 366, 451, #face contours\n",
    "57, 77, 89, 88, 178, 87, 14, 317, 402, 319, 307, #mouth\n",
    "64, 59, 44, 1, 457, 294,  #straight nose\n",
    "1, 4, 5, 195, 197, 6, 168, 8,  #vertical up\n",
    "190, 222, 224, 124, #left eye\n",
    "413, 441, 442, 443, 445 #right eye\n",
    "]\n",
    "\n",
    "def capture_yawn(image, face_landmarks, file_name):\n",
    "    imgH, imgW, _ = image.shape\n",
    "\n",
    "    # this is an example code where the person gets the nose\n",
    "    # landmark_0 = results.multi_face_landmarks[0].landmark[0]\n",
    "\n",
    "    # note: face_landmarks = results.multi_face_landmarks[i], just at different indexes\n",
    "    rows = []\n",
    "    index = 0\n",
    "    for index in range(len(face_landmarks.landmark)):\n",
    "        if index in faceConnect:\n",
    "            current_point = face_landmarks.landmark[index]\n",
    "            # print(current_point)\n",
    "            landmark_x = current_point.x * imgW \n",
    "            landmark_y = current_point.y * imgH\n",
    "            landmark_z = current_point.z * imgW #\n",
    "                \n",
    "            # print()\n",
    "            # print(\"X:\", landmark_x)\n",
    "            # print(\"Y:\", landmark_y)\n",
    "            # print(\"Z:\", landmark_z)\n",
    "            \n",
    "\n",
    "            row = [landmark_x, landmark_y, landmark_z]\n",
    "            # so yea, I am adding elements to the list called rows\n",
    "            rows += row  \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    # writing into the correct csv file\n",
    "    with open(file_name, mode='a', newline='') as f:\n",
    "        # I want to erase everything before inferring -- if we are in prediction mode\n",
    "        f.truncate(0)\n",
    "\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        #   for row in rows:\n",
    "        # writerow expects a list\n",
    "        csv_writer.writerow(rows) \n",
    "        print(\"The length of the row is \", len(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, I'll transform the images in the database into opencv values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_cam():   \n",
    "  # webcam input \n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as face_mesh:\n",
    "        \n",
    "        # to track the frame number, and skip some frames.\n",
    "        frame_number = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # Convert the BGR image to RGB.\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # To improve performance, mark the image as not writeable.\n",
    "            image.flags.writeable = False\n",
    "            results = face_mesh.process(image)\n",
    "\n",
    "            # Draw the face mesh annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    # Draw face landmarks.\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                        # connections = mp_face_mesh.FACEMESH_LEFT_EYE,\n",
    "                        landmark_drawing_spec=drawing_spec,\n",
    "                        connection_drawing_spec=drawing_spec)    \n",
    "                        \n",
    "#--------------------------------------------------------------\n",
    "# treating the different landmarks\n",
    "                    # using my function to specifically check for the nose\n",
    "                    # have the nose.csv file already ready!\n",
    "                    # I want to capture the nose every thirty frames\n",
    "                    if frame_number % 30 == 0:\n",
    "                        # if frame_number == 0:\n",
    "                        # I just want two dimensions, x and y, and I only have 1 coordinate (the nose)\n",
    "                        #     setup_file(\"nose.csv\", 2, 1)\n",
    "                        capture_nose(image, face_landmarks, \"nose.json\")\n",
    "\n",
    "                    # # I want to capture the eyes every 10 frames\n",
    "                    if frame_number % 10 == 0:\n",
    "                        # I want to run the setup file csv once\n",
    "                        if frame_number == 0:\n",
    "                            # 3 dimensions, and 12 coordinates that I am looking at\n",
    "                            setup_file(\"eye.csv\", 3, 12)\n",
    "                        capture_eye(image, face_landmarks, \"eye.csv\")\n",
    "                        # TODO here, I would run my machine learning model to check if the person has eyes closed\n",
    "                        # TODO although technically, when I'll be running inference, you don't want to be updating a csv file, better just pass the values.\n",
    "                        \n",
    "                    if frame_number % 10 == 0:\n",
    "                        if frame_number == 0:\n",
    "                            # 3 dimensions, and 478 coordinates that I am looking at\n",
    "                            setup_file(\"eye.csv\", 3, 478)\n",
    "                        capture_yawn(image, face_landmarks, \"yawn.csv\")\n",
    "                        #TODO here, I run a second machine learning model that tells if the person is yawning\n",
    "#======================\n",
    "\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('MediaPipe Face Mesh', image)\n",
    "            \n",
    "            # stop the process\n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "                break\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized an empty landmarks of size: 36\n",
      "The length of the row is  36\n",
      "Initialized an empty landmarks of size: 1434\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n",
      "The length of the row is  36\n",
      "The length of the row is  174\n"
     ]
    }
   ],
   "source": [
    "# num_val is the interval (number of frames) between each capture\n",
    "open_cam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then extract all of the eye landmarks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The %matplotlib inline command tells the IPython environment to draw the plots immediately after the current cell. The drawn plots are shown below the code and stored in the notebook document for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open live feed and start getting face coordinates, but feed each face coordinates to a different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Get the position of the nose for real-time tracking\n",
    "and check for the delta of the nose to track the person position on the screen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
