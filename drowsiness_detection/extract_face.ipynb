{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Project inspired by the following article: \n",
    "https://learnopencv.com/driver-drowsiness-detection-using-mediapipe-in-python/\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10384496/#:~:text=The%20overall%20performance%20of%20the,%25%20for%20left%2Dsided%20falling.\n",
    "\n",
    "database: \n",
    "https://www.kaggle.com/code/scratchpad/notebook18b582f770/edit\n",
    "\n",
    "Notice that I can choose the coordinates that you wish to analyze with opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intial imports: \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "# from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "# import streamlit as st\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    " \n",
    "mp_hands = mp.solutions.hands\n",
    "mp_facemesh = mp.solutions.face_mesh\n",
    "mp_drawing  = mp.solutions.drawing_utils\n",
    "denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first extract the necessary landmarks for the face and yawning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_file(csv_file, num_dimension = 3, num_coords = 33 + 21 + 21):\n",
    "    rows = []\n",
    "    #creating empty file in folder, i added the start_time in the name of the csv file, so that if a symbol appears many times in a video, it will still be created in two different csv files, just that they will have different starting times\n",
    "    # csv_file = f\"/users/aly/documents/programming/apps/machine learning/asl converter/training_models/mediapipe/demo_test/demo.csv\"\n",
    "    # csv_file=\"d:/personnel/other learning/programming/personal_projects/asl_language_translation/training_models/mediapipe/demo_test/demo.csv\"\n",
    "    # if os.path.exists(csv_file):\n",
    "    #     return \n",
    "\n",
    "\n",
    "\n",
    "# Setup CSV File for the videos\n",
    "# 21 right hand landmarks, 21 left hand landmarks, 33 pose landmarks\n",
    "    # num_coords = 33 + 21 + 21\n",
    "    landmarks = []\n",
    "\n",
    "    # we are only working with x, y\n",
    "    if num_dimension == 2:\n",
    "        for val in range(1, num_coords+1):\n",
    "            landmarks += ['x{}'.format(val), 'y{}'.format(val)]#.format(val), 'z{}'.format(val)]#, 'v{}'.format(val)]\n",
    "    \n",
    "    elif num_dimension == 3:\n",
    "        for val in range(1, num_coords+1):\n",
    "            landmarks += ['x{}'.format(val), 'y{}'.format(val).format(val), 'z{}'.format(val)]#, 'v{}'.format(val)]\n",
    "    \n",
    "    # I will assume they just want all the coordinates:\n",
    "    else:\n",
    "        landmarks += ['x{}'.format(val), 'y{}'.format(val).format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "\n",
    "    print(\"Initialized an empty landmarks of size:\", len(landmarks))\n",
    "\n",
    "    with open(csv_file, mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the landmarks chosen and writing only those out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    *,\n",
    "    img_dt,\n",
    "    img_eye_lmks=None,\n",
    "    img_eye_lmks_chosen=None,\n",
    "    face_landmarks=None,\n",
    "    ts_thickness=1,\n",
    "    ts_circle_radius=2,\n",
    "    lmk_circle_radius=3,\n",
    "    name=\"1\",\n",
    "):\n",
    "    # For plotting Face Tessellation\n",
    "    image_drawing_tool = img_dt \n",
    "     \n",
    "     # For plotting all eye landmarks\n",
    "    image_eye_lmks = img_dt.copy() if img_eye_lmks is None else img_eye_lmks\n",
    "     \n",
    "    # For plotting chosen eye landmarks\n",
    "    img_eye_lmks_chosen = img_dt.copy() if img_eye_lmks_chosen is None else img_eye_lmks_chosen\n",
    " \n",
    "    # Initializing drawing utilities for plotting face mesh tessellation\n",
    "    connections_drawing_spec = mp_drawing.DrawingSpec(\n",
    "        thickness=ts_thickness, \n",
    "        circle_radius=ts_circle_radius, \n",
    "        color=(255, 255, 255)\n",
    "    )\n",
    " \n",
    "    # Initialize a matplotlib figure.\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    fig.set_facecolor(\"white\")\n",
    " \n",
    "    # Draw landmarks on face using the drawing utilities.\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image=image_drawing_tool,\n",
    "        landmark_list=face_landmarks,\n",
    "        connections=mp_facemesh.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=connections_drawing_spec,\n",
    "    )\n",
    " \n",
    "    # Get the object which holds the x, y, and z coordinates for each landmark\n",
    "    landmarks = face_landmarks.landmark\n",
    " \n",
    "    # Iterate over all landmarks.\n",
    "    # If the landmark_idx is present in either all_idxs or all_chosen_idxs,\n",
    "    # get the denormalized coordinates and plot circles at those coordinates.\n",
    " \n",
    "    for landmark_idx, landmark in enumerate(landmarks):\n",
    "        if landmark_idx in all_idxs:\n",
    "            pred_cord = denormalize_coordinates(landmark.x, \n",
    "                                                landmark.y, \n",
    "                                                imgW, imgH)\n",
    "            cv2.circle(image_eye_lmks, \n",
    "                       pred_cord, \n",
    "                       lmk_circle_radius, \n",
    "                       (255, 255, 255), \n",
    "                       -1\n",
    "                       )\n",
    " \n",
    "        if landmark_idx in all_chosen_idxs:\n",
    "            pred_cord = denormalize_coordinates(landmark.x, \n",
    "                                                landmark.y, \n",
    "                                                imgW, imgH)\n",
    "            cv2.circle(img_eye_lmks_chosen, \n",
    "                       pred_cord, \n",
    "                       lmk_circle_radius, \n",
    "                       (255, 255, 255), \n",
    "                       -1\n",
    "                       )\n",
    " \n",
    "    # Plot post-processed images\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Face Mesh Tessellation\", fontsize=18)\n",
    "    plt.imshow(image_drawing_tool)\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"All eye landmarks\", fontsize=18)\n",
    "    plt.imshow(image_eye_lmks)\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(img_eye_lmks_chosen)\n",
    "    plt.title(\"Chosen landmarks\", fontsize=18)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture function for each part of the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_nose(image, results, face_landmarks, csv_file):\n",
    "    print(\"hi\")\n",
    "                    \n",
    "    # Get nose tip coordinates.\n",
    "    nose_tip = face_landmarks.landmark[1]\n",
    "    x, y = int(nose_tip.x * image.shape[1]), int(nose_tip.y * image.shape[0])\n",
    "    \n",
    "    # Print nose tip coordinates.\n",
    "    print(f\"Nose Tip Coordinates: (X: {x}, Y: {y})\")\n",
    "\n",
    "\n",
    "    # writing into the correct csv file\n",
    "    row = [x, y]\n",
    "    index = 0\n",
    "\n",
    "    #TODO use json file\n",
    "    # with open(csv_file, mode='a', newline='') as f:\n",
    "    #     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    #                     #   for row in rows:\n",
    "    #     # writerow expects a list\n",
    "    #     csv_writer.writerow(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "# Landmark points corresponding to left eye\n",
    "all_left_eye_idxs = list(mp_facemesh.FACEMESH_LEFT_EYE)\n",
    "# flatten and remove duplicates\n",
    "all_left_eye_idxs = set(np.ravel(all_left_eye_idxs)) \n",
    " \n",
    "# Landmark points corresponding to right eye\n",
    "all_right_eye_idxs = list(mp_facemesh.FACEMESH_RIGHT_EYE)\n",
    "all_right_eye_idxs = set(np.ravel(all_right_eye_idxs))\n",
    " \n",
    "# Combined for plotting - Landmark points for both eye\n",
    "all_idxs = all_left_eye_idxs.union(all_right_eye_idxs)\n",
    " \n",
    "# The chosen 12 points:   P1,  P2,  P3,  P4,  P5,  P6\n",
    "chosen_left_eye_idxs  = [362, 385, 387, 263, 373, 380]\n",
    "chosen_right_eye_idxs = [33,  160, 158, 133, 153, 144]\n",
    "all_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs\n",
    "\n",
    "def capture_eye(image):\n",
    "    imgH, imgW, _ = image.shape\n",
    "      # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "    #stop the process\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "        return False\n",
    "      \n",
    "    \n",
    "    # Running inference using static_image_mode \n",
    "    with mp_facemesh.FaceMesh(\n",
    "        static_image_mode=True,         # Default=False\n",
    "        max_num_faces=1,                # Default=1\n",
    "        refine_landmarks=False,         # Default=False\n",
    "        min_detection_confidence=0.5,   # Default=0.5\n",
    "        min_tracking_confidence= 0.5,   # Default=0.5\n",
    "    ) as face_mesh:\n",
    "        \n",
    "        results = face_mesh.process(image)\n",
    "    \n",
    "    # Indicates whether any detections are available or not.\n",
    "    print(bool(results.multi_face_landmarks))\n",
    "    if results.multi_face_landmarks:\n",
    "        landmark_0 = results.multi_face_landmarks[0].landmark[0]\n",
    "        print(landmark_0)\n",
    "        \n",
    "        landmark_0_x = landmark_0.x * imgW \n",
    "        landmark_0_y = landmark_0.y * imgH\n",
    "        landmark_0_z = landmark_0.z * imgW #\n",
    "                \n",
    "        print()\n",
    "        print(\"X:\", landmark_0_x)\n",
    "        print(\"Y:\", landmark_0_y)\n",
    "        print(\"Z:\", landmark_0_z)\n",
    "        \n",
    "        print()\n",
    "        print(\"Total Length of '.landmark':\", len(results.multi_face_landmarks[0].landmark))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_pose(results): #except for eyes and nose, i mean, doesn't really matter\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, I'll transform the images in the database into opencv values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_cam():   \n",
    "  # webcam input \n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as face_mesh:\n",
    "        \n",
    "        # to track the frame number, and skip some frames.\n",
    "        frame_number = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # Convert the BGR image to RGB.\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # To improve performance, mark the image as not writeable.\n",
    "            image.flags.writeable = False\n",
    "            results = face_mesh.process(image)\n",
    "\n",
    "            # Draw the face mesh annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    # Draw face landmarks.\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                        landmark_drawing_spec=drawing_spec,\n",
    "                        connection_drawing_spec=drawing_spec)    \n",
    "                        \n",
    "                    # using my function to specifically check for the nose\n",
    "                    # have the nose.csv file already ready!\n",
    "                    # I want to capture the nose every thirty frames\n",
    "                    if frame_number % 30 == 0:\n",
    "                        # I want to run the setup file csv once.\n",
    "                        if frame_number == 0:\n",
    "                            setup_file(\"nose.csv\", 2, 1)\n",
    "                        # I just want two dimensions, x and y, and I only have 1 coordinate (the nose)\n",
    "                        capture_nose(image, results, face_landmarks, \"nose.csv\")\n",
    "\n",
    "                    # # I want to capture the eyes every 10 frames\n",
    "                    if frame_number % 10 == 0:\n",
    "                        capture_eye(image, results, face_landmarks, \"eye.csv\")\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('MediaPipe Face Mesh', image)\n",
    "            \n",
    "            # stop the process\n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "                break\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "  \n",
    "    \n",
    "  # For webcam input:\n",
    "  # cap = cv2.VideoCapture(0)\n",
    "  # # ! old code that worked with hand gestures.\n",
    "  # while cap.isOpened():\n",
    "  #   success, image = cap.read()\n",
    "  #   if not success:\n",
    "  #     print(\"Ignoring empty camera frame.\")\n",
    "  #     # If loading a video, use 'break' instead of 'continue'.\n",
    "  #     continue\n",
    "\n",
    "  #     # Flip the image horizontally for a later selfie-view display, and convert\n",
    "  #     # the BGR image to RGB.\n",
    "  #   image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "  #     # To improve performance, optionally mark the image as not writeable to\n",
    "  #     # pass by reference.\n",
    "  #   image.flags.writeable = False\n",
    "\n",
    "  #   stop = capture_eye(image)\n",
    "  #   if stop:\n",
    "  #     break\n",
    "      #!results contains all the information about the image, in this case, we are looking at hands\n",
    "      # results = hands.process(image)\n",
    "      \n",
    "  # #!checks for both hands, and looks if there is data\n",
    "      # if results.multi_hand_landmarks:\n",
    "      #   #!extracting the information from the right hand\n",
    "      #   for hand in results.multi_hand_landmarks:\n",
    "\n",
    "      #     both_hand = hand\n",
    "      #     hand_row = list(np.array([[landmark.x, landmark.y] for ids, landmark in both_hand]).flatten())\n",
    "\n",
    "      # if results.multi_hand_landmarks:\n",
    "      #   for hand_landmarks in results.multi_hand_landmarks:\n",
    "      #     empty_row = []\n",
    "      #     # Here is How to Get All the Coordinates\n",
    "      #     for ids, landmrk in enumerate(hand_landmarks.landmark):\n",
    "      #         # print(ids, landmrk)\n",
    "      #         cx, cy= landmrk.x * image_width, landmrk.y*image_height, #landmrk.z\n",
    "      #         empty_row.append(cx)\n",
    "      #         empty_row.append(cy)\n",
    "      #         # empty_row.append(cz)\n",
    "      #         # print(cx, cy)\n",
    "      #     mp_drawing.draw_landmarks(\n",
    "      #         image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "      #     if index % num_val == 0:\n",
    "      #       rows.append(empty_row)\n",
    "      #     index += 1\n",
    "          # print(len(empty_row))\n",
    "        # #!else, I wanna just write 0 for the information about the hands.\n",
    "      # else:\n",
    "      #   #skip what is not usefulq \n",
    "      # #   both_hand_row = list(np.array([[0,0] for i in range(42)]).flatten())\n",
    "      #   # empty_row = [0 for i in range(42)]\n",
    "      #   # rows.append(empty_row)\n",
    "      #   continue\n",
    "\n",
    "      #!this is what shows the hands\n",
    "  #     cv2.imshow('MediaPipe Pose', image)\n",
    "\n",
    "  # # After the loop release the cap object \n",
    "  # cap.release() \n",
    "\n",
    "  # #closes all instance of the camera\n",
    "  # cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'open_cam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# num_val is the interval (number of frames) between each capture\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mopen_cam\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'open_cam' is not defined"
     ]
    }
   ],
   "source": [
    "# num_val is the interval (number of frames) between each capture\n",
    "open_cam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then extract all of the eye landmarks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The %matplotlib inline command tells the IPython environment to draw the plots immediately after the current cell. The drawn plots are shown below the code and stored in the notebook document for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open live feed and start getting face coordinates, but feed each face coordinates to a different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Get the position of the nose for real-time tracking\n",
    "and check for the delta of the nose to track the person position on the screen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
